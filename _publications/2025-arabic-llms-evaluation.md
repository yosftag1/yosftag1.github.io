---
title: "A Comparative Framework for Evaluating Arabic LLMs in Educational Conversational Applications"
collection: publications
category: manuscripts
permalink: /publication/2025-arabic-llms-evaluation
excerpt: "Rubric-based evaluation framework for Arabic LLMs in education. (Under Review)"
date: 2025-10-01
venue: 'Language Resources and Evaluation (Q1)'
link: /portfolio/llm-evaluation-framework/
paperurl: 'http://yosftag1.github.io/files/arabic-llms-evaluation.pdf'
citation: 'Shaimaa Lazem, Youssef Tageldin, Aly Nasr, et al. (2025). A Comparative Framework for Evaluating Arabic LLMs in Educational Conversational Applications. Language Resources and Evaluation (Under Review).'
---

This research presents a comparative framework designed to evaluate Arabic Large Language Models (LLMs) specifically for educational conversational applications, addressing the unique challenges of Arabic language processing in educational contexts.

## Evaluation Framework

![LLM Comparison](/images/projects/llm-evaluation/radar-models-full.png)
*Comparative evaluation of Arabic LLMs across multiple pedagogical dimensions*

## Key Contributions

- **Novel Rubric-Based Evaluation**: Multi-dimensional assessment beyond simple accuracy metrics
- **Arabic-Specific Focus**: Addresses unique challenges of Arabic NLP in education
- **Inter-Rater Reliability**: Robust validation ensuring consistent evaluation

![Inter-Rater Analysis](/images/projects/llm-evaluation/inter-rater-metrics.png)
*Statistical validation of evaluation consistency across human raters*

## Research Details

**Authors:** Shaimaa Lazem, **Youssef Tageldin**, Aly Nasr, et al.

**Status:** Under Review at Language Resources and Evaluation (Q1 Journal)

**Code Repository:** [github.com/yosftag1/arabic-llm-evaluation-framework](https://github.com/yosftag1/arabic-llm-evaluation-framework)

**Preprint:** Available upon request

**[View Full Portfolio Project](/portfolio/llm-evaluation-framework/)**
